\chapter{Припрема подарака}

Подаци  кориштени за тестирање приликом израде овог рада су јавно доступни подаци са сајта \textbf{\textit{http://stackexchange.com/}} из три области  - инжињерство, фитнес и хемија. Подаци су на \textbf{енглеском језику}. 

Ове три области су намерно тако одабране како би се повећала разноврсност речи. Речи из сродних научних грана користе сличну или исту терминологују па опасност од бирања питања и одговора из  сродних научних дисциплина лежи у чињеници да ће диверзитет корпуса бити мали.

Из сваке области узето је по 200 питаља и одговора, што представља базу од укупно 600 питања и 600 одговора. Овакав скуп података је затим подељен на два дела - тренинг део (360 питања и одговора) и тест део (240 питања и одговора).

Након испитивања на овом скупу података, решење је тестирано и на подацима доступпним са сајта \textit{answers.yahoo.com}. На овај начин, "`дуплим"' тестирањем, обезбеђује се независност закључака од природе података.

Подаци добијени са означених сајтова нису погодни за директну обраду те их је потребно делимично \textbf{прерадити} тј. \textbf{предпроцесирати}. 

Надаље следи опис коришћених метода предпроцесирања. Приликом тестирања коришћене су различите комбинације ових метода и мерени су њихови утицаји на крајње решење.


	\section{Уклаљаље HTML ознака и неалфанумеричких карактера }
	
Подаци који су достуони преко сајта \textbf{\textit{http://stackexchange.com/}} дати су у форми HTML текстова. То значи да се кроз основни текст питања и одговора провлаче додатни низови карактера који представљају HTML ознаке (тагове). Ове ознаке добијају смисао приликом генерисања веб странице, односно приликом форматирања текста питања и одговора на веб страницама. Међутим, за обраду текста у овом раду, те ознаке не значе ништа и додатно могу уносити забуну. Због тога их је потребно, пре било какве даље обраде текста, склонити. Најједноставнији начин да се то уради је преко \textit{регуларних израза}, обзиром на изглед и формат HTML ознака.


Са друге стране, у тексту се поред слова и бројева (\textit{алфанумерички карактери}) обавезно појављују и специјални знаци (ознаке које нису ни слова ни бројеви - \textit{неалфанумерички карактери}, међукојима су најчешћи интерпукцијски знакови . Поред њих, у скорије време, уз сваки текст је готово обавана појава и група специјалних знакова као што су нпр. смајлићи ( структуре конструисане од специјалних знакова које се могу интерпретирати као расположење нпр. :) - срећа, :( - туга  итд. ). Са становишта алгоритма моделовања тема, сви они, исто као и HTML ознаке, немају значење и потребно их је уклонити. Такође, најједноставнији начин да се то уради је применом регуларних израза.

	\section{Конвертовање свих слова текста у "`мала слова"'  енг. lowercase }

Писање речи великим или малим словима, као и започињање речи малим или великим словом, углавном има граматички смисао. При томе, у већини случајева, реч написана почетним великим и иста реч написана почетним  малим словом, имају исто значење. У машинској обради података, свако слово има другачију бинарну репрезентацију. Стога, реч написана великим почетним словом и иста реч написана малим почетним словом или свим великим словима, \textbf{нису исте речи} обзиром на то да имају различиту репрезентациу. Како би се ово избегло, пре било какве даље обраде, врши се конвертовање или пребацивање свих слова текста у мала слова. На тај начин, све речи састављене од истих слова и у истом редоследу, представљају \textbf{исту} реч, без обзира на граматичко значење речи или њену позицију у тексту. Избор конвертовања у мала слова је једнако оправдан као и  конвертовање у велика слова. Дакле, исти резултат би се добио и конвертовањем свих слова у велика слова. Међутим, у пракси, је чешће прихваћено пребацивање у мала слова па је такав приступ усвојен и у овом раду.
Наравно, постоје бројни примери када писање речи великим или малим почетним словом битно мења значење речи. На пример, у српском језику, реч \textit{Мила}, написана великим почетним словом, означава име особе, именуцу, док реч \textit{мила}, написана малим почетним словом означава придев. Исто тако реч, \textit{Јела} односи се на име особе док се реч \textit{јела} односи на врсту зимзеленог дрвета. 
Међутим, оваквих речи има довољно мало да је ризик од мењања значења речи, са аспекта алгоритма моделовања тема, прихватљив.


\section{Издвајање атомских елемената докумената - токена, енг. tokenization}

Манипулација читавим документима са аспекта алгоритма моделовања тема, нема смисла. Основна јединица манипулације ове врста алгоритама је \textbf{реч}.  Према томе, потребно је документе рашчланити на поједниначне речи. Процес издвајања основних елемената манипулације, тј. елемената од интереса, назива се издвајање \textbf{токена} или \textbf{токенизација}. Обзиром да су овде атомски елементи \textbf{речи} и да су речи одвојене размаком, процес токенизације је најједноставније извршити преко регуларних израза. 
У пакету Mallet се већ налазе готове класе  

	\section{Избациваље често коришћених речи енг. stop words}
		
У свакодневном говору често се употребљавају личне заменице, прилози, везници итд. Без њих, говор би био неодређен и неповезан па самим и неразумљивив. Међутим, у машинској обради текстуланих података, поготово у алгоритмима моделовања тема, оваква врста информација није неопходна. Пре свега, такве  речи не носи суштинско теметско значење обзиром да нису уско повезана ни са једном конкретном области. На пример, везници ,као што су у српском језку: и, или, па, али, због, ради итд. се употребљавају при писању докумената из свих научних грана и стога се ни за једну од тих речи не може дефинисати област припадања. Обзиром да је циљ из групе докумената издвијити \textbf{теме}, овакве речи су сувишне. Штавише, уносе додатну забуну при закључивању и, обзиром да су бројене, могу представљати велико оптерећење приликом обраде.	
Подаци коришћени у при изради овог рада су на енглеском језику те ће се надаље говорити о оваквој врсти речи у енглеском језику. Међутим, узимањем уобзор специфичности конкретног језика, иста разматрања могу се применти и на друге језике.

Избацивање често коришћених речи, stop words-ова, може се реализовати на више начина. 

Поузданији, универзалнији али и рачински захтевнији начин је алгоритамско проналажење таквих речи. Обизором да немају тематско значење, оне се појављују у великом броју у свим документима и темама. Једноставним бројањем појављивања речи у скупу свих докумената могу се уочити групе речи које се са изузетно високим фреквенцијама јављају у \textbf{свим документима}. Такве речи се могу сматрати за често коришћене те се, из описаних разлога, избацују.  Поред једноставног бројања речи, постоје и друге методе "` мерења "' присуства речи у корпусу. Једна од њих је и релативна фреквенција која зависи од дужине докумената. Међутим, обзором да овај приступ није коришћен у раду, у ове методе се неће дубље улазити.

Други, мање поуздан и релативно рачиунски незахтеван приступ је коришћење \textbf{листе често коришћених речи} које постоје за сваки језик. Те листе су јавно доступне и могу се пронаћи на бројним веб сајтовима. Обзором да је циљ рада био истраживање примене алгоиртама моделовања тема у специфичном проблему, овај приступ је прихватљивији. Пре свега, релативно се лако имплеменртира обзором да у Mallet-у већ постоји класа за уклањање ових речи. Са друге стране, овај корак предпроцесирања се на овај начин претвара у тривијалан и оставља простор за истраживање самог алгоритма моделовања тема. 
Највећа опасности од овог приступа је елеминација речи које, иако сврстане међу често коришћене, у датом скупу докумената ипак имају значење. Исто тако, обзиром да је листа предефинисана, могуће је изоставити речи које у конкретном скупу представљају често коришћене речи.

За поузданије и детаљнија истраживања, предлаже се примена прве методе. 
 
 	
	
	\section{Додавање синонима}
У циљу бољег дифренцирања тематике питања и одговора, за сваку реч је додато по 5  синонима. За проналажење синонима је коришћена WordNet библиотека. Основни разлог додавања синонима у скуп била је претпоставка да ће се на тај начин боље диференцирати теме, повећати диверзитет корпуса а самим тим и олакшати препознавање тачног одговора. Међутим, резулатати су показали управо супротно. Разлог томе што синониме треба тражити \textbf{по смислу} речи а не само по лексичком облику речи. Такође, фразе, којих има доста у свакодневном говорном и писаном енглеском језику, значајно могу да утичу на смисао питања/одговора. Када се они рашчлане на појединачне речи, могуће је да се и смисао промени.

	\section{Склањање наставака речи - енг. stemming}
	
Овај сегмент предпроцесирања је изузетно завистан од језика на коме је текст писан. Циљ је препознати различите облике исте речи и свести је на заједничку основу, која \textbf{не мора} да буде коренска. У енглеском језику, различити облици речи граде се додавањем разних \textbf{наставака} као што су \textit{s,ing,es ...}. Дакле, склањањем наставака речи редукује се диверзитет корпуса али се истовремено речи које имају исто значење само различит облик настао услед контекста реченице - рода, времена, врсте речи итд, своде на исту реч. У конкретној примени, овако нешто је неопходно за прецизно раздвајање тема. 
За српски језик овако нешто не би било могуће имплементирати на једноставан начин обзором на промену речи по падежима, лицима ( за глаголе ), родовима, бројевима и гласовне промене које се при томе дешавају. У тренутку писања рада, никакво готово решења за српски језик није постојало. Уколико предмет истраживања неког будућег рада буде био српски језик, потребно је написати ппроцедуре којима се речи језика ослобађају наставака, следећи граматичка правила.

	
	\section{Свођење на коренску реч - енг. lemmitization}

Свођење речи на коренску реч је слична метода методи склањања наставака речи, такође уско повезена са језиком који се обрађује. Једна од  разлика је што се склањање наставака речи може применити на речи које мењају облик додавањем наставака док се свођење на коренски реч може применити на све речи. На пример,  реч енг. better - бољи, при склањању наставака би остала непромењена  или би се свела на реч енг. bett,  док при свођењу на коренску реч она постаје енг. good - добар.
Друга, битнија разлика, је што се уклањање наставака  примењује на речи не водећи рачуна о контексту, док се свођењем на коренску реч може специфицирати и контекст речи. На пример, реч енг. meeting - може имати више значења. Као именица она означава \textit{састанак} док као глагол означава презент партицип глагола \textit{to meet}, у смислу \textit{сретати се, }. Уклањањем наставака, реч енг. meeting  у контексту именице као и у контексту глагола биће сведена на реч енг. meet. Код свођења речи на коренску реч, спецификацијом врсте речи могуће је реч енг. meeting оставити непромењену.
Такође, свођењем на кореснку реч могуће је неправилне глаголе енглеској језика свести на основни облик, што склањањем наставака није било могуће. 
Са аспекта алгоритма моделовања тема, свођење на коренску реч је прихватњивија метода, пре свега због могућности препознавања различитог облика истих речи када се они не граде додавањем наставака.
Обзором на једноставност имеплементације и брзину рада, чешће се користи скалањање наставка од свођења на коренску реч. У конкретном раду, обе методе су независно тестиране и равноправно коришћене у циљу добијања бољих резултата.
	
